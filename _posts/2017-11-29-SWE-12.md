---
title: "SWE: A Comprehensive Review"
layout: post
---

Software Engineering with Dr. Glenn Downing is an aptly named class. Unlike other classes here at UT, it doesn't claim to pertain to a subfield of computer science. Rather, it claims to be about software engineering as a whole. In that regard, 

It aims to provide a broad overview of the tools and techniques used in software engineering in the real world. It includes lectures about Python, SQL, and Regex syntax, readings, which are mostly about best practices, and hands-on experience creating a database website. Of course, there were also quizzes and tests over lecture material and readings. This review will address the effectiveness of various components of the course as well as how well they fit together.

## Lectures

In my opinion, the lectures are the most enjoyable part of the class. I enjoyed learning about Python trivia, as it shed light on the fundamental design choices that its authors made and helped me gain a deeper understanding and appreciation of the language. Questions about the syntax quirks covered in lecture tend to involve contrived code snippets that require close attention to detail to solve. While this may not seem very applicable in the real world, it is very much so because absolute clarity in understanding a language's syntax and semantics is extremely valuable when facing difficult debugging challenges, which arise fairly regularly in real-world programming.

The SQL and Regex lectures only seemed to scratch the surface in comparison to the level of detail we reached in Python. I'm not as familiar with SQL, but if I were in charge of expanding the scope of the Regex lectures, I would definitely cover greedy vs. non-greedy matching (as well as differences between Regex implementations!), alternations, the remaining quantifiers, non-capturing groups, nested (e.g. `abc ((\d\d)\d*)`) and quantified (e.g. `abc ((\d\d)+\d?)`) capturing groups, and backreferences. These topics, as well as Regex as a whole, are very potent for creating the types of challenging logic puzzles that are characteristic of Downing quizzes.

Students unfamiliar with Dr. Downing's lecture style—particularly the more shy ones—may be put off by his randomized roll call attendance that puts multiple people on the spot every lecture. Personally, I generally pay attention and follow along so I have no problem with the occasional participation he solicits. But if you tend to doze off or goof off during class, you may not enjoy the attention quite as much.

**Score: 10/10**

## Readings

The readings in this class cover a wide range of topics, including standard OOP principles, coding best practices, social commentary, and general college and career advice. To be honest, I didn't do any of the readings for this class. Granted, I was in Dr. Downing's other class a year ago and the readings were the same, but the bigger issue I have is that there is a high ratio of amount of reading to in-class application. They appeared on quizzes less consistently than in OOP when I took it, and I managed to do well enough on the reading questions on the first test anyway.

I appreciate the `StrategyPattern` series of lectures, which cover applications of the SOLID principles even though they don't mention the principles by name. But otherwise, the lectures didn't seem to be very concerned with the readings at all. In all other classes I have taken at UT, whenever there are readings for class, the lectures discuss the readings. This reinforces the material and caters to the learning habits of the greatest amount of students: those who learn by reading can do so, and those who learn by listening and watching can do so too.

**Score: 5/10**

## Projects

Out of all three major portions of the class, the projects ended up taking the most of my time and attention. I have a lot to say about them, so this section of the review will get a couple of subsections:

### Concept

The essential idea of the project is that each group creates a website that has information about different types of things that relate to each other, kind of like a really really small slice of Knowledge Graph. For example, a group might decide to build an IMDB clone that has information about films, actors, and genres. You are tasked with scraping a publicly available API for information you can use to populate your website.

While it is hailed as a dynamic website, I don't think it lives up to that label. Designing it as a single page application and fetching data using AJAX doesn't change the underlying reality that the nature of the data is that it doesn't change very often. You aren't hitting our API sources in realtime, instead querying as much as possible of their entire databases at once not more than five times throughout the semester. The website itself may be described as dynamic because you can filter, sort, and search the database, but the data itself is more or less completely static.

This leaves you with a website that is an inferior clone of an existing database website. Your website doesn't have the most updated information, it doesn't have the most robust user interface, and it can't handle as much traffic. (You'll run out of GCP credits.) Aside from being completely derivative and uninteresting, your project fundamentally relies on information that has been taken wholesale and without compensation from a source that has presumably worked very hard to collect it. This runs into anywhere from light grey areas to deep black areas with most of the databases freely available to us. I personally feel ethically conflicted about the work my group did while gathering data for our project, and I am not proud of the unoriginal work I published online.

If the idea is to create something I'm proud of enough to put on my resumé, my project for this class doesn't come remotely close. The two personal website projects that have made it onto my resumé are [JS-Y86](https://xsznix.github.io/js-y86/) and [Binaural](http://xsznix.github.io/binaural/). These two projects have passed the bar because both fill a niche that no previous website does: JS-Y86 provides an accessible simulator and web IDE for the Y86 educational programming language, and Binaural lets people generate binaural beats and noise with a DAW-like interface. (JS-Y86 is based on a previous work, but instead of being an inferior clone of it, it improves upon it in novel ways.)

Less restrictive project guidelines would pave the way for more original and memorable projects. A future student might come up with something fun that didn't exist before. This class could be the catalyst for the next [Pokemon Fusion](http://pokemon.alexonsager.net/), [FreeRice](http://freerice.com/#/english-vocabulary/1414), [Geoguessr](https://geoguessr.com/), or [Spurious Correlations](http://www.tylervigen.com/spurious-correlations). Each of these websites provides an interesting experience by looking at something from a different perspective and then sharing those new ideas with the world. That's a big part of what makes these successful websites memorable and differentiates them from the projects in this class. But in order for this class to push students to do something more exciting, it needs to encourage them to think outside the box, not inside it.

**Score: 1/10**

### Tools

If I were to create a real-world production-grade website that does the same thing as what my group did for our project, I would probably not use many of the tools we used for this class.

First of all, I wouldn't use React; it's overkill for a website of a mostly static nature, and it places an unnecessary bandwidth burden on the servers and forces visitors' computers to do more work than it ought to. I would prefer to do all of the templating on the server side (even though I'm a frontend guy, sometimes it's better to let the server do all the work) and only use AJAX for features beyond the scope of the project such as search autocomplete. React itself is a great tool—it's just not the best solution in this case.

Second, I wouldn't use PlanItPoker. The website only seems 80% complete: it has all the functionality it needs to do the one thing it's supposed to do, but the UX has several rough edges. Additionally, the way the project specs tell us to use PIP are unproductive. A website with this narrow of a scope should have about eight user stories total, and those stories should be more or less identical for every group:

* As a user, I want to browse through the models on the website.
* As a user, I want to see detailed information about the models on the website.
* As a user, I want the information on the website to be reasonably comprehensive.
* As a user, I want to know what the website is about from its landing page.
* As a user, I want to know who created the website, who the website is for, and what tools were used on the "About" page.
* As a developer, I want to retrieve data from the website using a RESTful API.
* As a developer, I want to see a visualization of *\[insert group name here\]*'s database.

There's no point on voting on estimates for features so granular that you can think of forty of them over the course of making a fairly simple cookie-cutter website. That's like ordering a meal at McDonald's and asking each worker there to estimate how long it'll take to grill the patty, take the patty off the grill, assemble the burger, fry the fries, put the fries in a container, put the burger and fries in a bag, and hand the bag across the counter.

Third, I wouldn't use GCP. Several groups encountered issues with billing and many commented on the complex dashboard interface. My group also encountered issues with deploy times that were multiple magnitudes slower than competitors' offerings. AWS is just as capable and beats GCP in all the aspects someone in this class would care about. And there are many other hosting solutions that would be suitable for this project; even Firebase could be suitable for projects in this class.

Fourth, I am perplexed at why a requirement to use GitBook popped up after most of each technical report had already been written. By that point in a project, you should have committed to using a certain set of tools a long time ago and you shouldn't migrate over to new tools unless you have a substantial reason to do so.

Many of the other tools are useful and I would recommend them to future students. GitHub, Trello, Slack, and Postman are all great tools and they are very suitable for SWE projects.

Throughout the semester, many groups asked to use different tools than the ones prescribed in the specs. This goes to show that different groups make different design decisions for different projects, and I think it would be good to allow groups to have more freedom in which tools to use for databases, hosting providers, project management, and communication. Of course, that means that it wouldn't be as easy to assign grades based on how much a group used a tool, but I'd argue that that's not a good criterion anyway. Tools should be natural productivity aids in a process, and requiring more issues on Trello than is useful, for example, forces a group to put in extra work to meet the requirement for using the tool even though the extra work did nothing to aid productivity. If groups could choose all of their own tools, a more effective way to assess how well they used their tools would be to ask them to explain and defend their choice of tools in their technical report and explain how they end up using the tools they choose.

**Score: 6/10**

### Technical Report

The technical report also perplexed me throughout the semester.

TODO
